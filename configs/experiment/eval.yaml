# @package _global_

global_cfg: # would be passed to actor, critic1, critic2, policy, env
  null

runner:
  _target_: src.runner.EvalRunner
  _partial_: true

diffuser:
  dir: /output/hydra_log/RL_Diffuser/runs/2023-09-05_09-44-51_629629/
  epoch: last

guide:
  _target_: diffuser.sampling.NoTrainGuideYLower

controller:
  # dir: /output/hydra_log/RL_Diffuser/runs/2023-09-05_09-13-20_740659/
  dir: /output/hydra_log/RL_Diffuser/multiruns/2023-08-30_08-31-28_530341/0
  epoch: last

policy:
  _target_: diffuser.sampling.GuidedPolicy
  _partial_: true
  # guide: in python
  # diffusion_model: in python
  # normalizer:  in python
  preprocess_fns: []
  # the following are **sample_kwargs
  sample_fn: 
    _target_: diffuser.sampling.n_step_guided_p_sample
    _partial_: true
  scale: 1000
  n_guide_steps: 2
  t_stopgrad: 2 # positive: grad[t < t_stopgrad] = 0; bigger is noise
  scale_grad_by_std: true


vis_freq: 50
max_render: 1


# common - for all tasks (task_name, tags, output_dir, device)
algorithm_name: "DefaultAlgName"
task_name: "RL_Diffuser"
tags: ["debug"]